{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yahooニュースをスクレイピングする関数を定義したので、シェアします。  \n",
    "データフレームを返してくれるので、データ分析に使えます！！  \n",
    "\n",
    "requests、BeautifulSoupを利用しています。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記号文字は分析をするにあたって邪魔になるため、記号を取り除く関数を定義します。\n",
    "# 下のYahooNews関数で使用します。\n",
    "def symbol_removal(soup):\n",
    "    soup = unicodedata.normalize(\"NFKC\", soup)\n",
    "    exclusion = \"「」『』【】〈〉《》≪≫、。・◇◆■●\" + \"\\n\" + \"\\r\" + \"\\u3000\" # 除去する記号文字を指定\n",
    "    soup = soup.translate(str.maketrans(\"\", \"\", string.punctuation  + exclusion))\n",
    "    return soup\n",
    "\n",
    "\n",
    "# Yahooニュースをスクレイピングする関数です。\n",
    "# 引数で指定した数の記事をとってきてデータフレームを返します。\n",
    "def YahooNews(n=30):\n",
    "    url = \"https://news.yahoo.co.jp/topics/top-picks\"\n",
    "    URL = \"https://news.yahoo.co.jp/\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    all_page_links = []\n",
    "    all_page_links.append(url)\n",
    "    all_links = []\n",
    "    while True:\n",
    "        try:\n",
    "            next = soup.find(\"li\", class_=\"pagination_item-next\").find(\"a\")[\"href\"]\n",
    "            next_link = URL + next\n",
    "            all_page_links.append(next_link)\n",
    "            next_res = requests.get(next_link)\n",
    "            soup = BeautifulSoup(next_res.text, \"html.parser\")\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    title_list = []\n",
    "    category_list = []\n",
    "    text_list = []\n",
    "    for url in all_page_links: # all_page_links: 全てのニュースのリスト\n",
    "            res = requests.get(url) # url: 25個分のニュースのリスト\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            page_soup = soup.find_all(\"a\", class_=\"newsFeed_item_link\")\n",
    "            for href in page_soup:\n",
    "                link = href[\"href\"] # link: 一つのニュースのリンク(本文は一部のみ)\n",
    "                all_links.append(link)\n",
    "    \n",
    "    if len(all_links) <= n:\n",
    "        n = len(all_links)\n",
    "    \n",
    "    i = 0\n",
    "    for link in all_links:\n",
    "        link_res = requests.get(link)\n",
    "        href_soup = BeautifulSoup(link_res.text, \"html.parser\")\n",
    "        try:\n",
    "            title = href_soup.find(\"h1\", class_=re.compile(\"^sc\")).string\n",
    "        except:\n",
    "            continue\n",
    "        title_link = href_soup.find(\"a\", class_=\"sc-fUKxqW\")[\"href\"] # title_link: 本文\n",
    "        res = requests.get(title_link)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        category = soup.find_all(\"li\", class_=\"current\")\n",
    "        try:\n",
    "            category = category[1].string\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            for tag in soup.find_all([\"a\"]):\n",
    "                tag.decompose()\n",
    "            try:\n",
    "                soup = soup.find(\"div\", class_=\"article_body\").get_text()\n",
    "                soup = symbol_removal(soup)\n",
    "                \n",
    "                text_list.append(soup)\n",
    "                title_list.append(title)\n",
    "                category_list.append(category)\n",
    "                i += 1 # 本文が正常に保存できたことをトリガーにしてカウントを一つ増やすことにします。\n",
    "                pro_bar = ('=' * math.ceil(i / (n / 20))) + (' ' * int((n / (n / 20)) - math.ceil(i / (n / 20))))\n",
    "                print('\\r[{0}] {1}記事'.format(pro_bar, i), end='')\n",
    "                if i >= n:\n",
    "                    df = pd.DataFrame({'title': title_list, 'category': category_list, 'text': text_list})\n",
    "                    return df\n",
    "            except:\n",
    "                continue\n",
    "    df = pd.DataFrame({'title': title_list, 'category': category_list, 'text': text_list})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、YahooNews関数を利用して記事をデータフレームに格納しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 517記事"
     ]
    }
   ],
   "source": [
    "df = YahooNews(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>損? あざとかわいい吉岡里帆</td>\n",
       "      <td>エンタメ</td>\n",
       "      <td>女優吉岡里帆27の2年ぶり2冊目の写真集里帆採取 by Asami Kiyokawa集英社...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>鬼滅の「聖地」潤う観光地</td>\n",
       "      <td>経済</td>\n",
       "      <td>コロナ禍にもかかわらず異例の大ヒットを記録している劇場版鬼滅の刃 無限列車編映画にとどまらず...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>電通G コロナで営業利益半減</td>\n",
       "      <td>経済</td>\n",
       "      <td>電通グループが10日発表した2020年19月期連結決算国際会計基準は売上高に当たる収益が9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>香港民主派議員、全員辞職</td>\n",
       "      <td>国際</td>\n",
       "      <td>12 北京共同新華社電によると中国の全人代常務委員会会議は11日香港立法会定数70の議員資格...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>専門家組織 全国的に感染増加</td>\n",
       "      <td>国内</td>\n",
       "      <td>新型コロナウイルス対策を助言する厚生労働省の専門家組織アドバイザリーボードの会合が11日開...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>ホワイトハウス周辺で4人刺傷</td>\n",
       "      <td>国際</td>\n",
       "      <td>米NBCテレビなどによると米大統領選でトランプ大統領とバイデン前副大統領の双方の支持者が集...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>一方的な勝利宣言 米の反応は</td>\n",
       "      <td>国際</td>\n",
       "      <td>FNNプライムオンラインアメリカ大統領選挙の投票日から一夜明けた4日午前10時前のワシントン...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>NY株続伸、一時600ドル超高</td>\n",
       "      <td>国際</td>\n",
       "      <td>ニューヨーク時事開票作業が進む米大統領選でトランプバイデン両候補の大接戦が続く中4日午前の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>セガサミー ゲーセン運営撤退</td>\n",
       "      <td>経済</td>\n",
       "      <td>セガサミーホールディングスは4日娯楽施設を運営する連結子会社セガエンタテインメント東京の株...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>中国、海上警備に武器使用へ</td>\n",
       "      <td>国際</td>\n",
       "      <td>北京共同中国全国人民代表大会全人代国会は4日海上警備を担う中国海警局の権限を定める海警法草...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title category  \\\n",
       "0     損? あざとかわいい吉岡里帆     エンタメ   \n",
       "1       鬼滅の「聖地」潤う観光地       経済   \n",
       "2     電通G コロナで営業利益半減       経済   \n",
       "3       香港民主派議員、全員辞職       国際   \n",
       "4     専門家組織 全国的に感染増加       国内   \n",
       "..               ...      ...   \n",
       "512   ホワイトハウス周辺で4人刺傷       国際   \n",
       "513   一方的な勝利宣言 米の反応は       国際   \n",
       "514  NY株続伸、一時600ドル超高       国際   \n",
       "515   セガサミー ゲーセン運営撤退       経済   \n",
       "516    中国、海上警備に武器使用へ       国際   \n",
       "\n",
       "                                                  text  \n",
       "0     女優吉岡里帆27の2年ぶり2冊目の写真集里帆採取 by Asami Kiyokawa集英社...  \n",
       "1    コロナ禍にもかかわらず異例の大ヒットを記録している劇場版鬼滅の刃 無限列車編映画にとどまらず...  \n",
       "2     電通グループが10日発表した2020年19月期連結決算国際会計基準は売上高に当たる収益が9...  \n",
       "3    12 北京共同新華社電によると中国の全人代常務委員会会議は11日香港立法会定数70の議員資格...  \n",
       "4     新型コロナウイルス対策を助言する厚生労働省の専門家組織アドバイザリーボードの会合が11日開...  \n",
       "..                                                 ...  \n",
       "512   米NBCテレビなどによると米大統領選でトランプ大統領とバイデン前副大統領の双方の支持者が集...  \n",
       "513  FNNプライムオンラインアメリカ大統領選挙の投票日から一夜明けた4日午前10時前のワシントン...  \n",
       "514   ニューヨーク時事開票作業が進む米大統領選でトランプバイデン両候補の大接戦が続く中4日午前の...  \n",
       "515   セガサミーホールディングスは4日娯楽施設を運営する連結子会社セガエンタテインメント東京の株...  \n",
       "516   北京共同中国全国人民代表大会全人代国会は4日海上警備を担う中国海警局の権限を定める海警法草...  \n",
       "\n",
       "[517 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./YahooNews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工夫した点：  \n",
    "- 引数を受け取って必要な数だけ記事をとってくることができるようにしました。\n",
    "- 進捗が確認できるようにしました。(取って来る記事数が多いと、かなり時間がかかるので。)\n",
    "- 引数に1000などの大きな数字を入れておくことで、Yahooニュースの記事を全て取得することができます。(yahooニュースは約500記事程度。)\n",
    "- 記号を除去する関数も実装し、YahooNews関数に組み込んでいます。\n",
    "\n",
    "### 妥協した点:   \n",
    "- たまーに複数ページに渡って書かれている記事があるが、その場合は最初の1ページだけとってくる仕様にしております。\n",
    "- コードがすごく長くなってしまいました。。もっと短くしたいです。\n",
    "- 最初に全てのページの記事のリンクを取得するようにしているので、引数に指定した記事数が少なくても、最初に30秒程時間がかかりますし、その間は進捗も表示されません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
