{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import jaconv\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.models import word2vec\n",
    "from janome.tokenizer import Tokenizer\n",
    "from pprint import pprint\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.aozora.gr.jp/access_ranking/2019_xhtml.html\"\n",
    "URL = \"\"\n",
    "res = requests.get(url)\n",
    "res.encoding = 'shift-jis'\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [url[\"href\"] for i, url in enumerate(soup.find_all(\"a\", target=\"_blank\")) if i < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "name = []\n",
    "text = []\n",
    "for url in url_list:\n",
    "    res = requests.get(url)\n",
    "    url_start = url[:37]\n",
    "    res.encoding = 'shift-jis'\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    for i, a in enumerate(soup.find_all(\"a\")):\n",
    "        if i == 7:\n",
    "            url_end = a[\"href\"][1:]\n",
    "    url = url_start + url_end\n",
    "    res = requests.get(url)\n",
    "    res.encoding = 'shift-jis'\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    title.append(soup.find(\"h1\").string)\n",
    "    name.append(soup.find(\"h2\").string)\n",
    "    for tag in soup.find_all([\"rt\", \"rp\"]):\n",
    "        tag.decompose()\n",
    "    text.append(soup.find(\"div\",{'class': 'main_text'}).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'タイトル': title, '作者': name, '本文': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>タイトル</th>\n",
       "      <th>作者</th>\n",
       "      <th>本文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>〔雨ニモマケズ〕</td>\n",
       "      <td>宮澤賢治</td>\n",
       "      <td>\\r\\n雨ニモマケズ\\r\\n風ニモマケズ\\r\\n雪ニモ夏ノ暑サニモマケヌ\\r\\n丈夫ナカラダ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>走れメロス</td>\n",
       "      <td>太宰治</td>\n",
       "      <td>\\r\\n　メロスは激怒した。必ず、かの邪智暴虐の王を除かなければならぬと決意した。メロスには...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>山月記</td>\n",
       "      <td>中島敦</td>\n",
       "      <td>\\r\\n　隴西の李徴は博学才穎、天宝の末年、若くして名を虎榜に連ね、ついで江南尉に補せられた...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>こころ</td>\n",
       "      <td>夏目漱石</td>\n",
       "      <td>\\n上　先生と私\\n\\n\\n一\\n\\r\\n　私はその人を常に先生と呼んでいた。だからここでも...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>羅生門</td>\n",
       "      <td>芥川龍之介</td>\n",
       "      <td>\\r\\n　ある日の暮方の事である。一人の下人が、羅生門の下で雨やみを待っていた。\\r\\n　広...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       タイトル     作者                                                 本文\n",
       "0  〔雨ニモマケズ〕   宮澤賢治  \\r\\n雨ニモマケズ\\r\\n風ニモマケズ\\r\\n雪ニモ夏ノ暑サニモマケヌ\\r\\n丈夫ナカラダ...\n",
       "1     走れメロス    太宰治  \\r\\n　メロスは激怒した。必ず、かの邪智暴虐の王を除かなければならぬと決意した。メロスには...\n",
       "2       山月記   中島敦   \\r\\n　隴西の李徴は博学才穎、天宝の末年、若くして名を虎榜に連ね、ついで江南尉に補せられた...\n",
       "3       こころ   夏目漱石  \\n上　先生と私\\n\\n\\n一\\n\\r\\n　私はその人を常に先生と呼んでいた。だからここでも...\n",
       "4       羅生門  芥川龍之介  \\r\\n　ある日の暮方の事である。一人の下人が、羅生門の下で雨やみを待っていた。\\r\\n　広..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"本文\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text.split('。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    tokens = t.tokenize(text)\n",
    "    return [token.surface for token in tokens \n",
    "        if token.part_of_speech.split(',')[0] not in['記号']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [extract_words(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メロス\n",
      "は\n",
      "激怒\n",
      "し\n",
      "た\n"
     ]
    }
   ],
   "source": [
    "for word in word_list[0]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(word_list, size=100, min_count=10, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.67513720e-03,  5.54723665e-03,  6.82930090e-03, -8.45239777e-03,\n",
       "       -8.97661131e-03, -1.91899780e-02, -3.35585210e-03,  5.31045604e-04,\n",
       "        4.23672464e-06,  1.17154121e-02,  1.10597163e-02, -2.35626809e-02,\n",
       "        1.11682490e-02, -7.05377432e-03, -5.89227770e-03, -1.67507473e-02,\n",
       "        1.12828715e-02,  1.77465868e-03, -7.49409257e-04, -1.10546115e-03,\n",
       "        1.49052758e-02,  1.39415618e-02,  2.01966539e-02, -1.91018893e-03,\n",
       "        1.48091661e-02, -5.08972723e-03, -3.64747085e-03,  4.71893093e-03,\n",
       "        2.27075745e-03,  1.82561786e-03, -6.60067052e-03,  1.11762341e-02,\n",
       "        5.95160807e-03, -1.09165478e-02,  6.56899996e-03,  8.87039118e-03,\n",
       "        5.14035160e-03, -1.08130826e-02,  5.64617454e-04, -1.43527025e-02,\n",
       "        1.65299606e-02,  5.31010982e-03, -6.09730976e-03, -4.09748871e-03,\n",
       "        9.52576846e-03,  1.04741380e-02, -4.49712668e-03,  9.95904580e-03,\n",
       "        6.63900515e-03,  1.14048813e-02,  7.61110336e-03,  6.25384087e-03,\n",
       "       -1.23766437e-02,  1.38531737e-02, -7.10387388e-03, -1.28624951e-02,\n",
       "        6.05524005e-03, -1.83418766e-02,  2.55089090e-03,  3.17219715e-03,\n",
       "        1.02715474e-03, -3.09351808e-03, -1.15092052e-02, -5.39987395e-03,\n",
       "        1.97487068e-04, -3.01896897e-03, -3.40446620e-03, -5.39403036e-03,\n",
       "       -8.70172959e-03,  1.75049691e-03, -9.14038683e-04, -6.54658023e-03,\n",
       "       -6.58487668e-03, -4.17749677e-03,  2.35973671e-02,  8.58188048e-03,\n",
       "       -4.43580607e-03, -1.14266761e-02, -4.68630157e-03,  7.36280577e-03,\n",
       "        3.65565461e-03,  7.15536904e-03,  1.54636893e-03, -2.90055200e-03,\n",
       "       -1.33704313e-03,  1.19472644e-03, -4.97817248e-03,  2.01304238e-02,\n",
       "       -5.99208346e-04, -1.47961816e-02,  3.71103466e-04,  2.51786434e-03,\n",
       "        5.86490333e-03, -2.40193494e-03,  1.93112362e-02,  1.59553636e-03,\n",
       "        2.77417409e-03,  3.85734439e-03,  9.91700869e-03,  3.38043552e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"メロス\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "は \t 0.9424130916595459\n",
      "て \t 0.9410027265548706\n",
      "の \t 0.9376859068870544\n",
      "に \t 0.9366027116775513\n",
      "た \t 0.9339988231658936\n",
      "を \t 0.9320712089538574\n",
      "私 \t 0.9307994246482849\n",
      "から \t 0.9264650344848633\n",
      "が \t 0.9255994558334351\n",
      "で \t 0.9244353771209717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ff0ed1119c57>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  results = model.most_similar(positive=\"信じ\", topn=10)\n"
     ]
    }
   ],
   "source": [
    "results = model.most_similar(positive=\"信じ\", topn=10)\n",
    "for result in results:\n",
    "    print(result[0], '\\t', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
